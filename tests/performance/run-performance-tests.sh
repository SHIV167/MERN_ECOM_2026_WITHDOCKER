#!/bin/bash

# Performance Testing Automation Script
# This script runs comprehensive performance tests using Artillery

echo "ğŸš€ Starting Performance Testing with Artillery"
echo "=============================================="

# Create results directory
mkdir -p test-results/performance
mkdir -p test-results/reports

# Set timestamp for reports
TIMESTAMP=$(date +"%Y-%m-%d-%H-%M-%S")
REPORT_DIR="test-results/performance/$TIMESTAMP"
mkdir -p "$REPORT_DIR"

echo "ğŸ“… Test Run: $TIMESTAMP"
echo "ğŸ“ Results Directory: $REPORT_DIR"

# Function to run a test and generate report
run_performance_test() {
    local test_name=$1
    local test_file=$2
    local output_file="$REPORT_DIR/${test_name}-results.json"
    local report_file="$REPORT_DIR/${test_name}-report.html"
    
    echo ""
    echo "ğŸ”¥ Running $test_name..."
    echo "ğŸ“„ Test file: $test_file"
    echo "ğŸ“Š Output: $output_file"
    
    # Run the test
    artillery run "$test_file" --output "$output_file"
    
    # Generate HTML report
    artillery report "$output_file" --output "$report_file"
    
    echo "âœ… $test_name completed"
    echo "ğŸ“ˆ Report generated: $report_file"
    
    # Extract key metrics
    echo "ğŸ“Š Key Metrics for $test_name:"
    artillery report "$output_file" | grep -E "(requests per second|response time|95th percentile)" || echo "No metrics available"
}

# Function to check if server is running
check_server() {
    echo "ğŸ” Checking if server is running..."
    if curl -s http://localhost:5000/api/health > /dev/null; then
        echo "âœ… Server is running"
        return 0
    else
        echo "âŒ Server is not running"
        echo "ğŸš€ Starting server..."
        npm run dev:server &
        SERVER_PID=$!
        echo "â³ Waiting for server to start..."
        sleep 10
        
        if curl -s http://localhost:5000/api/health > /dev/null; then
            echo "âœ… Server started successfully"
            return 0
        else
            echo "âŒ Failed to start server"
            return 1
        fi
    fi
}

# Function to generate summary report
generate_summary_report() {
    echo ""
    echo "ğŸ“‹ Generating Summary Report..."
    
    local summary_file="$REPORT_DIR/performance-summary.md"
    
    cat > "$summary_file" << EOF
# Performance Test Summary Report

**Date:** $(date)  
**Test Run:** $TIMESTAMP  
**Environment:** Development  

## Test Results Overview

### Load Test
- **File:** load-test.yml
- **Duration:** 4 minutes
- **Phases:** Warm up, Load test, Peak load
- **Report:** [Load Test Report]($(basename "$REPORT_DIR")/load-test-report.html)

### Stress Test
- **File:** stress-test.yml  
- **Duration:** 6 minutes
- **Phases:** Increasing load, High load, Maximum load, Stress test, Peak stress
- **Report:** [Stress Test Report]($(basename "$REPORT_DIR")/stress-test-report.html)

### Spike Test
- **File:** spike-test.yml
- **Duration:** 4 minutes  
- **Phases:** Baseline, Spike, Recovery, Major spike, Final recovery
- **Report:** [Spike Test Report]($(basename "$REPORT_DIR")/spike-test-report.html)

### Endurance Test
- **File:** endurance-test.yml
- **Duration:** 25 minutes
- **Phases:** Endurance test, Extended load, Sustained load
- **Report:** [Endurance Test Report]($(basename "$REPORT_DIR")/endurance-test-report.html)

## Key Performance Indicators

### Response Time Targets
- **Health Check:** < 100ms
- **Product List:** < 500ms  
- **Product Details:** < 300ms
- **Categories:** < 200ms
- **Authentication:** < 1000ms

### Throughput Targets
- **Normal Load:** 50+ requests/second
- **Peak Load:** 100+ requests/second
- **Stress Test:** 200+ requests/second

### Error Rate Targets
- **Normal Load:** < 1%
- **Peak Load:** < 2%
- **Stress Test:** < 5%

## Recommendations

### Performance Optimizations
1. **Database Indexing:** Ensure proper indexes on frequently queried fields
2. **Caching:** Implement Redis caching for product listings
3. **Connection Pooling:** Optimize database connection pool size
4. **Load Balancing:** Consider load balancer for high traffic scenarios

### Monitoring
1. **Response Time Monitoring:** Set up alerts for slow responses
2. **Error Rate Monitoring:** Alert on error rate thresholds
3. **Resource Monitoring:** Monitor CPU, memory, and database connections

### Next Steps
1. Run tests in staging environment
2. Compare with production baseline
3. Set up automated performance testing in CI/CD
4. Establish performance SLAs

---
*Report generated by Artillery Performance Testing Suite*
EOF

    echo "ğŸ“„ Summary report generated: $summary_file"
}

# Main execution
main() {
    echo "ğŸ¯ Performance Testing Suite"
    echo "============================"
    
    # Check server
    if ! check_server; then
        echo "âŒ Cannot proceed without running server"
        exit 1
    fi
    
    # Run tests
    echo ""
    echo "ğŸ§ª Running Performance Tests..."
    echo "=============================="
    
    run_performance_test "load-test" "tests/performance/load-test.yml"
    run_performance_test "stress-test" "tests/performance/stress-test.yml"
    run_performance_test "spike-test" "tests/performance/spike-test.yml"
    run_performance_test "endurance-test" "tests/performance/endurance-test.yml"
    
    # Generate summary
    generate_summary_report
    
    # Cleanup
    if [ ! -z "$SERVER_PID" ]; then
        echo "ğŸ›‘ Stopping server..."
        kill $SERVER_PID
    fi
    
    echo ""
    echo "ğŸ‰ Performance Testing Complete!"
    echo "==============================="
    echo "ğŸ“ All reports saved to: $REPORT_DIR"
    echo "ğŸ“Š View summary: $REPORT_DIR/performance-summary.md"
    echo "ğŸŒ Open reports in your browser to view detailed results"
    
    # Open reports in browser (optional)
    if command -v open > /dev/null; then
        echo "ğŸŒ Opening summary report..."
        open "$REPORT_DIR/performance-summary.md"
    fi
}

# Run main function
main "$@"
